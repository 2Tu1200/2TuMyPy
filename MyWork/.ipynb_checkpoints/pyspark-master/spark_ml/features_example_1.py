"""
VectorAssembler is a transformer that combines a given list of columns into a single vector column. It is useful for combining raw features and features generated by different feature transformers into a single feature vector, in order to train ML models like logistic regression and decision trees. VectorAssembler accepts the following input column types: all numeric types, boolean type, and vector type. In each row, the values of the input columns will be concatenated into a vector in the specified order.
"""
import findspark
findspark.init()

from pyspark import SparkContext
from pyspark.sql import SQLContext, SparkSession
from pyspark.sql.functions import col
from pyspark.ml import Pipeline
from pyspark.ml.linalg import Vectors
from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder

sc = SparkContext("local", "Features - Example")
sqlContext = SQLContext(sc)
spark = SparkSession.builder.getOrCreate()
        
ml_data_path = "C:\\PySpark\\data\\ml\\"    
train = spark.read.csv(ml_data_path + "train_titanic.csv", header = True)

# String to float on some columns of the dataset : creates a new dataset
train = train.select(col("Survived"),col("Sex"),col("Embarked"),col("Pclass").cast("float"),col("Age").cast("float"),col("SibSp").cast("float"),col("Fare").cast("float"))

# dropping null values
train = train.dropna()

# Spliting in train and test set. Beware : It sorts the dataset
(traindf, testdf) = train.randomSplit([0.7,0.3])

genderIndexer = StringIndexer(inputCol="Sex", outputCol="indexedSex")
embarkIndexer = StringIndexer(inputCol="Embarked", outputCol="indexedEmbarked")
surviveIndexer = StringIndexer(inputCol="Survived", outputCol="indexedSurvived")

#genderIndexer.fit(train).transform(train).select("Sex", "indexedSex").show()

genderEncoder = OneHotEncoder(inputCol="indexedSex", outputCol="sexVec")
embarkEncoder = OneHotEncoder(inputCol="indexedEmbarked", outputCol="embarkedVec")

assembler = VectorAssembler(inputCols=["Pclass","sexVec","Age","SibSp","Fare","embarkedVec"], outputCol="features")

pipeline = Pipeline(stages=[genderIndexer, embarkIndexer, surviveIndexer, genderEncoder,embarkEncoder, assembler]) 

# Train model.  This also runs the indexers.
model = pipeline.fit(train)
 

model.transform(train).select("Embarked", "indexedEmbarked", "embarkedVec", "features").show()
model.transform(train).show()

spark.stop()